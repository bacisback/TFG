Previous section was an introduction to RKHS's, now in this section we will use them define a homogeneity test in terms of the embeddings of the probability measures. This test consist in maximizing the measure of discrepancy between functions that belong to a certain family $\mathcal{F}$ which must be rich enough to detect all the possible differences between the two probability measures. Most content for this chapter is taken from \cite{MMD1} and \cite{MMD2}.

Now we will introduce what homogeneity is in terms of functions, this will be used in order to assure that MMD is an homogeneity test, then we will give a definition for MMD which this section will revolve around.
\begin{lem}[Homogeneity]
Given two Borel probability measures $\mathbb{P}$ and $\mathbb{Q}$  are equal if and only if $\mathbb{E}f(X) = \mathbb{E}f(Y)$  $\forall f \in \mathbb{C(X)}(X)$
$X \sim \mathbb{P} \text{ and } Y \sim \mathbb{Q}$
\end{lem}
Defining a metric which satisfies this is a complex task, in this section our goal is to present one approach which can be taken to define an homogeneity test using mean embeddings in functional spaces. 

Let $\mathcal{F}$ be a class of functions f: $X \rightarrow \mathbb{R}$ the MMD based on $\mathcal{F}$ is

$$\gamma(\mathbb{P},\mathbb{Q}) = MMD(\mathcal{F},\mathbb{P},\mathbb{Q}) =  \sup\limits_{f\in\mathcal{F}}\{\mathbb{E}f(X) -\mathbb{E}f(Y)\}$$

This $\mathcal{F}$ must be rich enough for it to ensure that $\mathbb{P} = \mathbb{Q} \leftrightarrow \gamma(\mathbb{P},\mathbb{Q}) = 0$. And restrictive enough for the empirical estimate to converge quickly as the sample size increases. As we can see calculating the supremum is not an approachable task, therefore now we will focus on how to calculate this without measuring each function in $\mathcal{F}$.

Now we will introduce the concept of Mean Embedding which will help us to give a manageable definition for MMD. Some concepts which are useful for a complete understanding of this concepts are introduced in Appendix \ref{dems} Section \ref{P:MMD}

\begin{defn}[D:ME]
\textsf{\textbf{Mean embedding}}

Given a probability distribution $\mathbb{P}$ we will define the mean embedding of $\mathbb{P}$ as an element $\mu_{p} \in \mathcal{H}$ such that

$$\mathbb{E}(f(X))=<f,\mu_{\mathbb{P}}>_{\mathcal{H}}, \forall f \in \mathcal{H}$$

Which is equivalent to:

$$\mu_{\mathbb{P}} = \mathbb{E}(k(\cdot,X))$$

This is shown in Appendix \ref{dems} Section \ref{P:MMD}
\end{defn}

\subsection{Expressing MMD by mean embeddings}
Now that we have defined what a mean embedding is, we will express MMD in terms of  mean embeddings, this will help us to manage MMD as a tangible concept and not an abstract entity.

Given the conditions of Lemma A.1.1 ($\mu_{\mathbb{P}} \text{ and } \mu_{\mathbb{Q}}$ exist) then:

$X \sim \mathbb{P} \mu_{\mathbb{P}} \equiv \mathbb{E}_{X\sim \mathbb{P}}(k(\cdot,X))$ $Y \sim \mathbb{Q} \mu_{\mathbb{Q}} \equiv \mathbb{E}_{Y\sim \mathbb{Q}}(k(\cdot,Y))$

and:

$$MMD(\mathcal{F},\mathbb{P}, \mathbb{Q}) = \norm{\mu_{\mathbb{P}} - \mu_{\mathbb{Q}}}_{\mathcal{H}}$$

This is the first step, now that we've expressed MMD in terms of mean embeddings we will use \ref{D:ME} to express MMD in terms of expectations of kernels which is something we can compute

\begin{prop}
Given:
$X,X' \sim \mathbb{P} \text{ and } Y,Y' \sim \mathbb{Q}$ and X and Y are independent then:

$$MMD^{2}(\mathcal{F},\mathbb{P},\mathbb{Q}) = \mathbb{E}(k(X,X')) + \mathbb{E}(k(Y,Y')) - 2\mathbb{E}k(X,Y).$$

\end{prop}

This is proven in Appendix \ref{dems} Section \ref{P:MMD}, in addition in Subsection \ref{P:HTMMD} we've shown that MMD defines an homogeneity test, this is to showcase that this measure is defines an homogeneity test.

\subsection{Application to independence test}

Now that we've introduced MMD we will develop an independence criterion which will be conduced by the following idea:
Given $\mathcal{X} \sim \mathbb{P}$ and $\mathcal{Y} \sim \mathbb{Q}$ whose joint distribution is $\mathbb{P}_{\mathcal{XY}}$ then the test of independence between these variables will be determining if $\mathbb{P}_{\mathcal{XY}}$ is equal to the product of the marginals $\mathbb{P}\mathbb{Q}$. Therefore:

$\mathcal{MMD}(\mathcal{F}, \mathbb{P}_{\mathcal{XY}},\mathbb{P}\mathbb{Q}) = 0$ if and only if $\mathcal{X}$ and $\mathcal{Y}$ are independent.
To characterize this independence test we need to introduce a new RKHS, which is a tensor product of the RKHSâ€™s in which the marginal distributions of the random variables are embedded. Let $\mathcal{X}$ and $\mathcal{Y}$ be two topological spaces and let k and l be kernels on these spaces, with respective RKHS $\mathcal{H}$ and $\mathcal{G}$. Let us denote as $\upsilon((x, y), (x' , y ' ))$ a kernel on the product space $\mathcal{X}\times\mathcal{Y}$ with RKHS $\mathcal{H}_{\upsilon}$. This space is known as the tensor product space $\mathcal{H}\times\mathcal{G}$. Tensor product spaces are explained in detail in Appendix \ref{dems} Section \ref{P:MMD} Subsection \ref{P:TP}.

Now we will introduce some definitions which will be used in the next section to define the independence test HSIC and show that it's equivalent to MMD.

\paragraph{Useful definitions for the following content}
$$\mathbb{E}_{\mathcal{X}}f(\mathcal{X}) = \int f(x)d\mathbb{P}(x)$$
$$\mathbb{E}_{\mathcal{Y}}f(\mathcal{Y}) = \int f(y)d\mathbb{Q}(y)$$
$$\mathbb{E}_{\mathcal{X}\mathcal{Y}}f(\mathcal{X}\mathcal{Y}) = \int f(x,y)d\mathbb{P}_{\mathcal{X}\mathcal{Y}}(x,y)$$

Using this notation, the mean embedding of $\mathbb{P}_{\mathcal{X}\mathcal{Y}}$ and $\mathbb{P}\mathbb{Q}$ are:

$$\mu_{\mathbb{P}_{\mathcal{X}\mathcal{Y}}} = \mathbb{E}_{\mathcal{X}\mathcal{Y}}\upsilon((\mathcal{X},\mathcal{Y}),)$$
$$\mu_{\mathbb{P}\mathbb{Q}} = \mathbb{E}_{\mathcal{X}\mathcal{Y}}\upsilon((\mathcal{X},\mathcal{Y}),)$$
In terms of these embeddings:

\begin{equation}[MMDequiv]{MMD definition}
\mathcal{MMD}(\mathcal{F}, \mathbb{P}_{\mathcal{XY}},\mathbb{P}\mathbb{Q}) = \norm{
\mu_{\mathbb{P}_{\mathcal{X}\mathcal{Y}}}-
\mu_{\mathbb{P}\mathbb{Q}} 
}_{\mathbb{H}_{\upsilon}}
\end{equation}

This last definition will be used in the next section because it'll make really easy the equivalence between HSIC and MMD